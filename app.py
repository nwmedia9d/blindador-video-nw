import streamlit as st
import tempfile
import os
import numpy as np

# IMPORTA√á√ïES DA NOVA VERS√ÉO (MOVIEPY 2.0+)
# N√£o usamos mais 'moviepy.editor'
from moviepy import VideoFileClip, concatenate_videoclips, AudioArrayClip, CompositeAudioClip
import moviepy.video.fx as vfx
import moviepy.audio.fx as afx

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Blindador PRO 2.0", page_icon="üõ°Ô∏è", layout="centered")

st.title("üõ°Ô∏è Blindagem de V√≠deo (Vers√£o 2.0)")
st.info("‚ÑπÔ∏è Sistema atualizado para rodar no Python moderno do Streamlit Cloud.")

# --- CONTROLES LATERAIS ---
st.sidebar.header("üéõÔ∏è Configura√ß√µes")
threshold = st.sidebar.slider("Sensibilidade (Threshold)", 0.01, 0.10, 0.03, 0.005)
chunk_len = st.sidebar.slider("Resolu√ß√£o (s)", 0.01, 0.10, 0.05)

st.sidebar.markdown("---")
use_noise = st.sidebar.checkbox("Injetar Ru√≠do (-50dB)", value=True)
use_eq = st.sidebar.checkbox("Equaliza√ß√£o Anti-IA", value=True)
use_speed = st.sidebar.checkbox("Acelera√ß√£o (1.05x)", value=True)

# --- FUN√á√ÉO GERADORA DE RU√çDO ---
def generate_noise(duration, fps=44100, volume=0.01):
    # Gera ru√≠do branco aleat√≥rio
    noise = np.random.uniform(-volume, volume, (int(duration * fps), 2))
    return AudioArrayClip(noise, fps=fps)

# --- PROCESSAMENTO PRINCIPAL ---
def process_video(uploaded_file):
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(uploaded_file.read())
    
    status_text = st.empty()
    bar = st.progress(0)
    
    try:
        # Carrega o v√≠deo
        video = VideoFileClip(tfile.name)
        audio = video.audio
        
        # 1. AN√ÅLISE DE SIL√äNCIO
        status_text.text("üîç 1/4: Mapeando sil√™ncios...")
        intervals = []
        speaking = False
        start_time = 0
        
        # Convertendo √°udio para array para an√°lise r√°pida
        # MoviePy 2.0 lida com audio arrays de forma diferente, vamos usar itera√ß√£o segura
        duration = video.duration
        
        for i, t in enumerate(np.arange(0, duration, chunk_len)):
            # Extrair trecho de √°udio
            chunk = audio.subclipped(t, min(t + chunk_len, duration))
            
            # Analisar volume (RMS ou Max)
            # Em v2, max_volume() ainda existe, mas convertendo para array √© mais seguro
            chunk_data = chunk.to_soundarray(fps=22050)
            if chunk_data.size > 0:
                vol = np.max(np.abs(chunk_data))
            else:
                vol = 0

            if vol >= threshold:
                if not speaking:
                    speaking = True
                    start_time = t
            else:
                if speaking:
                    speaking = False
                    intervals.append((max(0, start_time - 0.02), min(t + 0.02, duration)))
            
            if i % 10 == 0:
                prog = min(30, int((t/duration)*30))
                bar.progress(prog)

        if speaking:
            intervals.append((start_time, duration))
            
        if not intervals:
            return None, "Erro: Nenhum √°udio detectado acima do limite. Tente diminuir o Threshold."

        # 2. CORTE E CONCATENA√á√ÉO
        status_text.text(f"‚úÇÔ∏è 2/4: Removendo pausas ({len(intervals)} cortes)...")
        # Nota: 'subclipped' √© o novo 'subclip' seguro em v2
        clips = [video.subclipped(start, end) for start, end in intervals]
        final_clip = concatenate_videoclips(clips)
        bar.progress(50)

        # 3. ACELERA√á√ÉO (Sintaxe V2)
        if use_speed:
            # Em v2, usamos with_effects e MultiplySpeed
            final_clip = final_clip.with_effects([vfx.MultiplySpeed(1.05)])

        # 4. ENGENHARIA DE √ÅUDIO
        status_text.text("üéöÔ∏è 3/4: Aplicando blindagem de √°udio...")
        current_audio = final_clip.audio
        
        if use_eq:
            # Sintaxe v2 para filtros de √°udio
            # HighPass e LowPass
            effects = [
                afx.AudioHighPass(100), # Remove graves
                afx.AudioLowPass(8000)  # Remove super agudos
            ]
            current_audio = current_audio.with_effects(effects)
        
        if use_noise:
            noise_clip = generate_noise(final_clip.duration, fps=44100, volume=0.005)
            current_audio = CompositeAudioClip([current_audio, noise_clip])
            
        final_clip.audio = current_audio
        bar.progress(70)

        # 5. RENDERIZA√á√ÉO
        status_text.text("üíæ 4/4: Renderizando (Aguarde)...")
        output_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name
        
        # preset='ultrafast' ajuda a n√£o dar timeout no servidor gratuito
        final_clip.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            preset='ultrafast',
            threads=4,
            logger=None
        )
        
        bar.progress(100)
        status_text.text("‚úÖ V√≠deo Blindado e Pronto!")
        
        video.close()
        return output_path, None

    except Exception as e:
        return None, f"Erro T√©cnico: {str(e)}"

# --- FRONTEND ---
uploaded_file = st.file_uploader("Envie seu v√≠deo (.mp4)", type=["mp4"])

if uploaded_file is not None:
    st.video(uploaded_file)
    
    if st.button("üõ°Ô∏è INICIAR BLINDAGEM", type="primary"):
        with st.spinner('Processando... (Isso pode levar alguns minutos)'):
            result_path, error = process_video(uploaded_file)
            
            if error:
                st.error(error)
            else:
                st.success("Sucesso!")
                with open(result_path, "rb") as f:
                    st.download_button(
                        label="‚¨áÔ∏è BAIXAR V√çDEO BLINDADO",
                        data=f,
                        file_name="video_blindado_v2.mp4",
                        mime="video/mp4"
                    )
